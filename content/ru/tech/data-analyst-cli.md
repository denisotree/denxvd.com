---
title: CLI для специалистов по данным
date: 2024-12-19
Description: На первый взгляд, работа в терминале может показаться устаревшей. Но освоив командную строку, вы получите мощные инструменты для повышения эффективности и автоматизации повседневных задач. В этой статье я расскажу про те инструменты и подходы, которыми пользуюсь сам.
tags:
  - bash
  - linux
  - macos
  - terminal
categories: 
featured_image: /tech/cli-data-analyst.jpg
featured_image_caption: 
summary: На первый взгляд, работа в терминале может показаться устаревшей. Но освоив командную строку, вы получите мощные инструменты для повышения эффективности и автоматизации повседневных задач. В этой статье я расскажу про те инструменты и подходы, которыми пользуюсь сам.
disableComments: true
draft: false
---
На первый взгляд, работа в терминале (или в консоли, ведь CLI - это com может показаться устаревшей. Многие специалисты предпочитают графические интерфейсы, считая их более удобными и интуитивно понятными. Однако освоение командной строки (CLI) открывает доступ к мощным инструментам, которые могут значительно повысить вашу продуктивность и автоматизировать рутинные задачи. В этой статье я расскажу о ключевых инструментах и подходах, которые использую сам в своей работе.

P.S. Хотя эта статья скорее для начинающих специалистов, опытные аналитики так же могут найти тут полезные кейсы для использования уже знакомых им утилит.

---
## Почему вообще стоит тратить на это время?

Работа в командной строке может показаться сложной, особенно если вы привыкли к графическим интерфейсам. Однако у работы в терминале есть несколько неоспоримых преимуществ:

1. **Скорость**: Многие задачи выполняются быстрее через командную строку, чем через графический интерфейс.
2. **Автоматизация**: Скрипты и команды позволяют автоматизировать повторяющиеся процессы.
3. **Гибкость**: CLI предоставляет доступ к функциям и настройкам, которые недоступны через GUI.
4. **Кроссплатформенность**: Большинство инструментов CLI работают как на Linux, так и на macOS (а иногда и на Windows).

В идеальном случае можно прийти к ситуации, когда вам вообще не нужно отрывать руки от клавиатуры и пользоваться мышкой. Это невероятно ускоряет работу и улучшает концентрацию на задаче.

---
## Основные инструменты CLI для специалистов по данным

### 1. SH | BASH | ZSH и базовые утилиты

Одним словом - оболочка командной строки. Наверное любому техническому специалисту в сфере информационных технологий нужно уметь в ней работать.
Важно понимать как переходить по дереву каталогов, как смотреть на содержимое файлов, как создавать, удалять и перемещать файлы и папки. Это базовые навыки, которые необходимы для работы в любой операционной системе на основе Unix (Linux, macOS).

Основные команды:
- `cd`: переход между каталогами.
- `ls`: просмотр содержимого каталога.
- `cat`, `less`, `head`, `tail`: просмотр содержимого файлов.
- `mkdir`: создание нового каталога.
- `rm`: удаление файлов или каталогов.
- `mv`: перемещение или переименование файлов.
- `cp`: копирование файлов.

Пример:

```bash
cd /path/to/directory
ls -l
cat file.txt
```

Важно так же изучить работу с переменными окружения, перенаправлением потоков (`>`, `<`, `|`), а также приобрести навыки написания простых bash-скриптов для автоматизации задач.

---
### 2. grep, sed и awk

Эти инструменты являются основой для обработки текстовых данных в командной строке.

- **grep**: поиск строк в файлах по шаблону.
```bash
# Найдет все строки с текстом "error" в файле log.txt.
grep "error" log.txt
```

- **sed**: потоковый редактор для поиска и замены текста.
```bash
# Заменяет "old_text" на "new_text" во всем файле.
sed 's/old_text/new_text/g' file.txt > new_file.txt
```

- **awk**: инструмент для обработки текстовых данных и работы с колонками.
```bash
# Выводит первую и третью колонку из CSV-файла.
awk -F ',' '{print $1, $3}' data.csv
```

Эти инструменты особенно полезны при работе с большими текстовыми файлами или логами.

---
### 3. JQ

`jq` - это инструмент для обработки и форматирования JSON-данных в командной строке. JSON (JavaScript Object Notation) является одним из самых популярных форматов для хранения и передачи данных, особенно в веб-разработке и API. `jq` позволяет легко извлекать, фильтровать и преобразовывать данные из JSON-файлов или потоков.

Примеры использования:

- **Форматирование JSON для удобного чтения**:
```bash
cat data.json | jq
```

- **Извлечение определенного поля**:
```bash
# Извлекает значение поля "name" из JSON.
cat data.json | jq '.name'
```

- **Фильтрация данных**:
```bash
# Извлекает все элементы массива, где поле "age" больше 30.
cat data.json | jq '.[] | select(.age > 30)'
```

- **Комбинирование данных**:
```bash
# Извлекает имя и возраст из каждого объекта в массиве.
cat data.json | jq '.[] | {name: .name, age: .age}'
```

`jq` — это один из самы часто используемых инструментов, потому что необходимость получить отформатированный JSON возникает часто, а это наверное самый быстрый способ для этого 

---

### 4. VisiData

`VisiData` - невероятно мощный инструмент для работы с табличными данными. Я написал отдельную статью о том, почему вам стоит начать применять его для решения своих текущих задач. Прочитать ее можно [тут]({{< relref "visidata" >}}).

`Visidata` сочетает в себе мощь командной строки с удобством работы с таблицами, что делает его незаменимым инструментом для специалистов по данным. `VisiData` поддерживает множество форматов данных, включая CSV, Excel, JSON, SQLite и даже удаленные источники данных.

#### Почему стоит использовать VisiData?

1. **Производительность**: Загрузка и обработка больших объемов данных происходит мгновенно.
2. **Гибкость**: Возможность фильтровать, сортировать и агрегировать данные прямо в терминале.
3. **Удобство**: Простые горячие клавиши позволяют быстро выполнять сложные операции.
4. **Кроссплатформенность**: Работает на всех основных операционных системах.

#### Основные возможности:

- **Просмотр данных**:
```bash
# Открывает файл `data.csv` в интерактивном режиме.
vd data.csv
```

- **Фильтрация строк**:
Нажмите `z|` и введите условие для фильтрации строк (например, `age > 30`).

- **Сортировка данных**:
Нажмите `[`, чтобы отсортировать данные по текущей колонке `ASC` и `]` для сортировки `DESC`.

- **Агрегация данных**:
Нажмите `Shift+F`, чтобы быстро сгруппировать данные по определенной колонке и посчитать `count` по умолчанию. Други функции агрегации доступны по нажатию на `+` .

- **Экспорт результатов**:
После обработки данных можно сохранить результат в новый файл, нажав `Ctl+s`. Можно ввести новое имя файла, или сохранить изменения в том же.

---
### 5. htop

`htop` — это улучшенная версия команды `top`, которая показывает информацию о процессах, использовании CPU, памяти и других ресурсах системы. 

Пример:

```bash
htop
```

Очень важная утилита, чтобы в реальном времени видеть как ваши скрипты и ноутбуки потребляют ресурсы компьютера, а так же находить удобно "убивать" зависшие процессы.

---
### 6. rsync

`rsync` — это мощный инструмент для синхронизации файлов между локальными и удаленными системами. Он поддерживает инкрементальную передачу данных, что делает его очень эффективным.

Пример:

```bash
# Синхронизирует локальный каталог с удаленным сервером.
rsync -avz /local/path user@remote:/remote/path
```

---
### 7. SSH

`ssh` — это инструмент для удаленного подключения к серверам. Он позволяет безопасно управлять удаленными системами через терминал.

Пример:

```bash
ssh user@remote_host
```

Для копирования файлов можно использовать `scp`:

```bash
scp file.txt user@remote_host:/path/to/destination/
```

---
### 8. VIM и VIM-like редакторы (NeoVim, Helix)

`VIM` (Vi IMproved) — это один из самых популярных текстовых редакторов в командной строке. Но многие испытывают проблемы даже с тем, чтобы просто выйти из него.
Да, можно использовать `Nano` или другие более современные редакторы текста, но ни один не дает столько власти над текстом как `vim` (разве что `emacs`, но это уже другая история).

**Зачем это нужно?**

Все так же, чтобы можно было делать то, что нам нужно, не выходя из консоли. Я не призываю превращать `vim`, a точнее `neovim` в полноценную IDE, хотя сам так и поступил. Но даже базовое знание vim позволит вам например превратить столбец строк

```txt
val1
val2
val3
```

 в значения, разделенные запятыми:

```txt
"val1", "val2", "val3",
```

В `vim`  достаточно ввести команду:

```vim
:%s/.*/"&"/ | %s/\n/, /
```

и нажать Enter

- `:%s/.*/"&"/` оборачивает все строки в файле в двойные кавычки
- `%s/\n/, /` заменяет переносы строк `\n` на запятые с пробелом

Такие задачи возникают постоянно и если у вс под рукой есть быстрый и удобный способ их решить, то почему бы им не воспользоваться.

---
### 9. wget и curl

Это безумно полезные инструменты, знание которых обязательно, если вы так или иначе сталкиваетесь с задачами парсинга и выгрузки данных. Утилиты похожи по своему функционалу, что я покажу ниже, но все же не заменяют друг друга, а скорее дополняют.

- Примеры использования `curl` в работе:

```bash
# Скачивает файл `file.txt` в текущую директорию.
curl -O https://example.com/file.txt
```

```bash
# Скачивает файл и сохраняет его под именем `my_file.txt`.
curl -o my_file.txt https://example.com/file.txt
```

```bash
# Отправляет POST-запрос с параметрами `param1` и `param2`.
curl -X POST -d "param1=value1&param2=value2" https://api.example.com/endpoint
```

```bash
# Отправляет JSON-данные на сервер.
curl -X POST -H "Content-Type: application/json" -d '{"key1":"value1","key2":"value2"}' https://api.example.com/endpoint
```

```bash
# Добавляет заголовки, такие как токен авторизации и тип содержимого.
curl -H "Authorization: Bearer TOKEN" -H "Content-Type: application/json" https://api.example.com/data
```

```bash
# Скачивает сразу два файла.
curl -O https://example.com/file1.txt -O https://example.com/file2.txt
```

```bash
# Выводит только заголовки ответа (например, статус HTTP, дату, тип содержимого).
curl -I https://example.com
```

```bash
# Следует за редиректами до конечного URL и показывает все промежуточные этапы 
curl -vL https://short.url/link
```

```bash
# Использует базовую HTTP-аутентификацию для доступа к защищенному файлу.
curl -u username:password -O https://example.com/protected-file.txt
```

```bash
# Возобновляет загрузку файла с того места, где она была прервана.
curl -C - -O https://example.com/large-file.zip
```

- Примеры использования `wget` в работе:

```bash
# Скачивает файл в текущую директорию.
wget https://example.com/file.txt
```

```bash
# Сохраняет файл под именем `my_file.txt`.
wget -O my_file.txt https://example.com/file.txt
```

```txt
# Создайте файл `urls.txt` со списком URL:

https://example.com/file1.txt
https://example.com/file2.txt
https://example.com/file3.txt
```

```bash
# Затем выполните:
wget -i urls.txt

Скачаются все файлы из списка
```

```bash
# Игнорирует SSL сертификаты, если они не действительны
wget --no-check-certificate https://example.com/file.txt
```

```bash
# Возобновляет загрузку файла с того места, где она была прервана.
wget -c https://example.com/large-file.zip
```

```bash
# Скачивает весь сайт для оффлайн-просмотра.
wget --mirror --convert-links --adjust-extension --page-requisites --no-parent https://example.com/
```

- `--mirror`: включает рекурсивную загрузку.
- `--convert-links`: преобраз

Вы скажете, что все это можно сделать в python и я соглашусь. Но если вам не нужно делать сложный конвейер данных, то комбинация из cli инструментов будет сильно удобнее.

---
### 10. Git

С удивлением обнаружил, что с `git` умеют работать далеко не все, а тем более в терминале. Потому не будет лишним проговорить как и зачем его использовать.
`Git` — это система контроля версий, которая позволяет отслеживать изменения в коде, работать над проектами в команде и управлять различными версиями файлов. Для специалистов по данным `git` становится незаменимым инструментом, особенно при работе с Python-скриптами, dbt-моделями, Jupyter-ноутбуками или любыми другими проектами, связанными с данными.

Основные команды `git`:

- **Инициализация репозитория**:
```bash
# Создает новый локальный репозиторий.
git init
```

- **Клонирование удаленного репозитория**:
```bash
# Копирует удаленный репозиторий на ваш компьютер.
git clone https://github.com/user/repo.git
```
  
- **Просмотр статуса репозитория**:
```bash
# Показывает текущие изменения в файлах и их статус (измененные, добавленные, удаленные).
git status
```

- **Добавление изменений в индекс (staging area)**:
```bash
# Добавляет файл в индекс для последующего коммита.
git add file_name
```

```bash
# Чтобы добавить все файлы:
git add .
```

- **Создание коммита**:
```bash
# Сохраняет изменения с описанием.
git commit -m "Описание изменений"
```

- **Просмотр истории коммитов**:
```bash
# Показывает список всех коммитов в репозитории.
git log
```

- **Отправка изменений на удаленный сервер**:
```bash
# Отправляет изменения из локального репозитория в удаленный (например, на GitHub).
git push origin branch_name
```

- **Получение изменений из удаленного репозитория**:
```bash
# Синхронизирует локальный репозиторий с удаленным.
git pull origin branch_name
```

- **Создание новой ветки**:
```bash
# Создание новой ветки изменений с названием "branch_name" 
git branch branch_name
```
  
- **Переключение между ветками**:
```bash
# Переключение на ветку "branch_name"
git checkout branch_name
```

- **Слияние веток**:
```bash
# Если мы хотим влить например в ветку master изменения, сделанные в ветке "branch_name"
git checkout master 
git merge branch_name

# Если мы хотим влить в ветку "branch_name" актуальные изменения, сделанные в ветке "master", например, для тестов и пулл реквеста

git checkout branch_name
git merge master
```

#### Почему `git` важен для специалистов по данным?

1. **Совместная работа**: В проектах по анализу данных часто участвуют несколько человек. `Git` позволяет эффективно управлять изменениями и избегать конфликтов.
2. **История изменений**: Вы всегда можете вернуться к предыдущей версии кода или данных.
3. **Эксперименты с кодом**: Используя ветки, можно тестировать новые гипотезы или подходы без риска повредить основную версию проекта.
4. **Интеграция с платформами**: Такие платформы, как GitHub или GitLab, позволяют удобно делиться проектами, проводить код-ревью и автоматизировать процессы через CI/CD.

Освоение `git` — это не только про управление кодом, но и про организацию работы над проектами. Это инструмент, который помогает вам быть более продуктивным и уверенным в своих действиях при работе с данными.

---
## Дополнительные советы по работе в CLI

1. **Используйте автодополнение**: Многие оболочки (например, Bash или Zsh) поддерживают автодополнение команд и аргументов.
2. **Создавайте алиасы**: Упростите часто используемые команды с помощью алиасов в вашем `.bashrc` или `.zshrc`.

   ```bash
   alias ll="ls -la"
   alias gs="git status"
   ```
   
3. **Изучите регулярные выражения**: Они помогут вам эффективно работать с текстовыми данными.
4. **Документируйте свои команды**: Создавайте скрипты для повторяющихся задач.


## Post Scriptum

Это, конечно же, не окончательный список полезных утилит командной строки. Их количество огромно и каждый день появляются новые. Я перечислил те, которые могут вам помочь в повседневной работе специалиста по данным. Освоение этих инструментов — это инвестиция в вашу продуктивность и профессионализм. Даже если вы только начинаете свой путь в анализе данных, знание CLI-инструментов даст вам конкурентное преимущество и позволит решать задачи быстрее и эффективнее.

Не бойтесь экспериментировать, пробовать новые утилиты и подходы. Терминал (командная строка) — это мощный инструмент, который может стать вашим лучшим помощником в работе с данными. Удачи!
